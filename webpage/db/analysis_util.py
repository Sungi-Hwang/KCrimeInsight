import pandas as pd
import pymysql
import warnings
warnings.filterwarnings('ignore', category=UserWarning)
from scipy.stats import pearsonr, spearmanr, linregress

def get_correlation_data(selected_type='ì „ì²´'):
    conn = pymysql.connect(
        host='192.168.0.234',
        user='teamuser',
        password='team1234',
        db='1team_database',
        charset='utf8mb4'
    )
    region_map = {
        'ì„œìš¸íŠ¹ë³„ì‹œ': 'ì„œìš¸',
        'ë¶€ì‚°ê´‘ì—­ì‹œ': 'ë¶€ì‚°',
        'ëŒ€êµ¬ê´‘ì—­ì‹œ': 'ëŒ€êµ¬',
        'ì¸ì²œê´‘ì—­ì‹œ': 'ì¸ì²œ',
        'ê´‘ì£¼ê´‘ì—­ì‹œ': 'ê´‘ì£¼',
        'ëŒ€ì „ê´‘ì—­ì‹œ': 'ëŒ€ì „',
        'ìš¸ì‚°ê´‘ì—­ì‹œ': 'ìš¸ì‚°',
        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': 'ì„¸ì¢…',
        'ê²½ê¸°ë„': 'ê²½ê¸°',
        'ê°•ì›íŠ¹ë³„ìì¹˜ë„': 'ê°•ì›',
        'ì¶©ì²­ë¶ë„': 'ì¶©ë¶',
        'ì¶©ì²­ë‚¨ë„': 'ì¶©ë‚¨',
        'ì „ë¼ë¶ë„': 'ì „ë¶',
        'ì „ë¶íŠ¹ë³„ìì¹˜ë„': 'ì „ë¶',
        'ì „ë¼ë‚¨ë„': 'ì „ë‚¨',
        'ê²½ìƒë¶ë„': 'ê²½ë¶',
        'ê²½ìƒë‚¨ë„': 'ê²½ë‚¨',
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': 'ì œì£¼'
    }

    if selected_type == 'ì „ì²´':
        sql = """
            SELECT ì‹œë„ AS ì§€ì—­, SUM(`ê°„ì´ì£¼ì ` + `ê¸°íƒ€` + `ë…¸ë˜í´ëŸ½` + `ë£¸ì‚´ë¡±` + `ë¹„ì–´_ë°”_ì‚´ë¡±` + `ì¹´ë°”ë ˆ`) AS ì—”í„°ìˆ˜
            FROM entertain_bar 
            GROUP BY ì‹œë„
        """
    else:
        sql = f"""
            SELECT ì‹œë„ AS ì§€ì—­, SUM(`{selected_type}`) AS ì—”í„°ìˆ˜ 
            FROM entertain_bar 
            GROUP BY ì‹œë„"""

    ent_df = pd.read_sql(sql, conn)
    ent_df['ì§€ì—­'] = ent_df['ì§€ì—­'].map(region_map)

    crime_df = pd.read_sql("""
        SELECT ì§€ì—­, SUM(í­ë ¥ë²”ì£„) AS í­ë ¥ë²”ì£„ê±´ìˆ˜
        FROM crime_data_2011_2022_edit
        WHERE ì—°ë„=2022 
        GROUP BY ì§€ì—­
    """, conn)

    merged_df = pd.merge(ent_df, crime_df, on='ì§€ì—­')

    if len(merged_df) < 2:
        conn.close()
        return None, 0, 0, 0, 0, [], []

    pearson_corr, pearson_p = pearsonr(merged_df['ì—”í„°ìˆ˜'], merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'])
    spearman_corr, spearman_p = spearmanr(merged_df['ì—”í„°ìˆ˜'], merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'])
    regression = linregress(merged_df['ì—”í„°ìˆ˜'], merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'])

    regression_line = [{"x": x, "y": regression.slope * x + regression.intercept} for x in merged_df['ì—”í„°ìˆ˜']]
    scatter_data = [{"x": row['ì—”í„°ìˆ˜'], "y": row['í­ë ¥ë²”ì£„ê±´ìˆ˜']} for _, row in merged_df.iterrows()]

    conn.close()

    return (merged_df, 
            round(pearson_corr, 3), round(pearson_p, 4),
            round(spearman_corr, 3), round(spearman_p, 4),
            scatter_data, regression_line)

def get_correlation_ratio_data(selected_type='ì „ì²´'):
    conn = pymysql.connect(
        host='192.168.0.234',
        user='teamuser',
        password='team1234',
        db='1team_database',
        charset='utf8mb4'
    )
    region_map = {
        'ì„œìš¸íŠ¹ë³„ì‹œ': 'ì„œìš¸',
        'ë¶€ì‚°ê´‘ì—­ì‹œ': 'ë¶€ì‚°',
        'ëŒ€êµ¬ê´‘ì—­ì‹œ': 'ëŒ€êµ¬',
        'ì¸ì²œê´‘ì—­ì‹œ': 'ì¸ì²œ',
        'ê´‘ì£¼ê´‘ì—­ì‹œ': 'ê´‘ì£¼',
        'ëŒ€ì „ê´‘ì—­ì‹œ': 'ëŒ€ì „',
        'ìš¸ì‚°ê´‘ì—­ì‹œ': 'ìš¸ì‚°',
        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': 'ì„¸ì¢…',
        'ê²½ê¸°ë„': 'ê²½ê¸°',
        'ê°•ì›íŠ¹ë³„ìì¹˜ë„': 'ê°•ì›',
        'ì¶©ì²­ë¶ë„': 'ì¶©ë¶',
        'ì¶©ì²­ë‚¨ë„': 'ì¶©ë‚¨',
        'ì „ë¼ë¶ë„': 'ì „ë¶',
        'ì „ë¶íŠ¹ë³„ìì¹˜ë„': 'ì „ë¶',
        'ì „ë¼ë‚¨ë„': 'ì „ë‚¨',
        'ê²½ìƒë¶ë„': 'ê²½ë¶',
        'ê²½ìƒë‚¨ë„': 'ê²½ë‚¨',
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': 'ì œì£¼'
    }

    # ìœ í¥ì—…ì†Œ ë°ì´í„°
    if selected_type == 'ì „ì²´':
        sql = """
            SELECT ì‹œë„ AS ì§€ì—­, SUM(`ê°„ì´ì£¼ì ` + `ê¸°íƒ€` + `ë…¸ë˜í´ëŸ½` + `ë£¸ì‚´ë¡±` + `ë¹„ì–´_ë°”_ì‚´ë¡±` + `ì¹´ë°”ë ˆ`) AS ì—”í„°ìˆ˜
            FROM entertain_bar 
            GROUP BY ì‹œë„
        """
    else:
        sql = f"""
            SELECT ì‹œë„ AS ì§€ì—­, SUM(`{selected_type}`) AS ì—”í„°ìˆ˜ 
            FROM entertain_bar 
            GROUP BY ì‹œë„
            """

    ent_df = pd.read_sql(sql, conn)
    ent_df['ì§€ì—­'] = ent_df['ì§€ì—­'].map(region_map)

    # ë²”ì£„ ë°ì´í„°
    crime_df = pd.read_sql("""
        SELECT ì§€ì—­, SUM(í­ë ¥ë²”ì£„) AS í­ë ¥ë²”ì£„ê±´ìˆ˜
        FROM crime_data_2011_2022_edit
        WHERE ì—°ë„=2022 GROUP BY ì§€ì—­
    """, conn)

    # ì¸êµ¬ ë°ì´í„°
    pop_df = pd.read_sql("""
        SELECT region AS ì§€ì—­, `2022_15ì„¸ì´ìƒì¸êµ¬__ì²œëª…_` AS ì¸êµ¬ìˆ˜
        FROM merged_data_jh
    """, conn)


    # ë³‘í•©
    merged_df = pd.merge(ent_df, crime_df, on='ì§€ì—­')
    merged_df = pd.merge(merged_df, pop_df, on='ì§€ì—­')

    if len(merged_df) < 2:
        conn.close()
        return None, 0, 0, 0, 0, [], []

    # ë¹„ìœ¨ ê³„ì‚°
    merged_df['ì—…ì†Œìˆ˜ë¹„ìœ¨'] = merged_df['ì—”í„°ìˆ˜'] / merged_df['ì¸êµ¬ìˆ˜']
    merged_df['ë²”ì£„ê±´ìˆ˜ë¹„ìœ¨'] = merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'] / merged_df['ì¸êµ¬ìˆ˜']

    # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
    pearson_corr, pearson_p = pearsonr(merged_df['ì—…ì†Œìˆ˜ë¹„ìœ¨'], merged_df['ë²”ì£„ê±´ìˆ˜ë¹„ìœ¨'])
    spearman_corr, spearman_p = spearmanr(merged_df['ì—…ì†Œìˆ˜ë¹„ìœ¨'], merged_df['ë²”ì£„ê±´ìˆ˜ë¹„ìœ¨'])

    regression = linregress(merged_df['ì—…ì†Œìˆ˜ë¹„ìœ¨'], merged_df['ë²”ì£„ê±´ìˆ˜ë¹„ìœ¨'])
    regression_line = [{"x": x, "y": regression.slope * x + regression.intercept} for x in merged_df['ì—…ì†Œìˆ˜ë¹„ìœ¨']]
    scatter_data = [{"x": row['ì—…ì†Œìˆ˜ë¹„ìœ¨'], "y": row['ë²”ì£„ê±´ìˆ˜ë¹„ìœ¨']} for _, row in merged_df.iterrows()]

    conn.close()
    return (merged_df, round(pearson_corr, 3), round(pearson_p, 4),
            round(spearman_corr, 3), round(spearman_p, 4),
            scatter_data, regression_line)

def get_density_correlation_data(selected_type='ì „ì²´',  ent_basis='area', crime_basis='area', remove_outliers=False):
    try:
        conn = pymysql.connect(
            host='192.168.0.234',
            user='teamuser',
            password='team1234',
            database='1team_database',
            charset='utf8mb4'
        )
        
        # ì—”í„° ì—…ì†Œ ë°ì´í„°
        ent_sql = """
            SELECT ì‹œë„, ì‹œêµ°êµ¬, 
                (ê°„ì´ì£¼ì  + ê¸°íƒ€ + ë…¸ë˜í´ëŸ½ + ë£¸ì‚´ë¡± + ë¹„ì–´_ë°”_ì‚´ë¡± + ì¹´ë°”ë ˆ) AS ì—”í„°ìˆ˜
            FROM entertain_bar
        """
        ent_df = pd.read_sql(ent_sql, conn)

        # ë²”ì£„ ë°ì´í„° (í­ë ¥ë²”ì£„ë§Œ)
        crime_sql = """
            SELECT ì‹œë„, ì‹œêµ°êµ¬, SUM(ë°œìƒê±´ìˆ˜) AS í­ë ¥ë²”ì£„ê±´ìˆ˜
            FROM crime_area_2023
            WHERE ë²”ì£„ëŒ€ë¶„ë¥˜ = 'í­ë ¥ë²”ì£„'
            GROUP BY ì‹œë„, ì‹œêµ°êµ¬
        """
        crime_df = pd.read_sql(crime_sql, conn)

        # ë©´ì  ë°ì´í„°
        area_sql = """
            SELECT ìì¹˜êµ¬ëª…, `ë©´ì (kmÂ²)` AS ë©´ì 
            FROM origin_ground_area
        """
        area_df = pd.read_sql(area_sql, conn)
        # ì‹œë„, ì‹œêµ°êµ¬ ë¶„ë¦¬
        area_df[['ì‹œë„', 'ì‹œêµ°êµ¬']] = area_df['ìì¹˜êµ¬ëª…'].str.split(' ', n=1, expand=True)


        # ì¸êµ¬ ë°ì´í„°
        pop_sql = """
            SELECT ì‹œë„ëª… AS ì‹œë„, ì‹œêµ°êµ¬ëª… AS ì‹œêµ°êµ¬, SUM(ê³„) AS ì¸êµ¬ìˆ˜
            FROM origin_population_age
            GROUP BY ì‹œë„ëª…, ì‹œêµ°êµ¬ëª…
        """
        pop_df = pd.read_sql(pop_sql, conn)


        # ë³‘í•©
        merged_df = pd.merge(ent_df, crime_df, on=['ì‹œë„', 'ì‹œêµ°êµ¬'], how='inner')
        merged_df = pd.merge(merged_df, area_df[['ì‹œë„', 'ì‹œêµ°êµ¬', 'ë©´ì ']], on=['ì‹œë„', 'ì‹œêµ°êµ¬'], how='inner')
        merged_df = pd.merge(merged_df, pop_df[['ì‹œë„', 'ì‹œêµ°êµ¬', 'ì¸êµ¬ìˆ˜']], on=['ì‹œë„', 'ì‹œêµ°êµ¬'], how='inner')
        
        # ë°€ì§‘ë„ ê³„ì‚°
        if ent_basis == 'area':
            merged_df['ì—…ì†Œë°€ì§‘ë„'] = merged_df['ì—”í„°ìˆ˜'] / merged_df['ë©´ì ']
        else:
            merged_df['ì—…ì†Œë°€ì§‘ë„'] = merged_df['ì—”í„°ìˆ˜'] / merged_df['ì¸êµ¬ìˆ˜']

        if crime_basis == 'area':
            merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'] = merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'] / merged_df['ë©´ì ']
        else:
            merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'] = merged_df['í­ë ¥ë²”ì£„ê±´ìˆ˜'] / merged_df['ì¸êµ¬ìˆ˜']
        if len(merged_df) < 2:
            return None, 0, 0, 0, 0, [], [], 0, 0
        
        merged_df['ìì¹˜êµ¬ëª…'] = merged_df['ì‹œë„'] + ' ' + merged_df['ì‹œêµ°êµ¬']
        
        scatter_data = [
            {"x": row["ì—…ì†Œë°€ì§‘ë„"], "y": row["í­ë ¥ë²”ì£„ë°€ì§‘ë„"], "title": row["ìì¹˜êµ¬ëª…"]}
            for _, row in merged_df.iterrows()
        ]

        # ğŸ”¥ ì•„ì›ƒë¼ì´ì–´ ì œê±° (ì„ íƒ)
        if remove_outliers:
            Q1_x = merged_df['ì—…ì†Œë°€ì§‘ë„'].quantile(0.25)
            Q3_x = merged_df['ì—…ì†Œë°€ì§‘ë„'].quantile(0.75)
            IQR_x = Q3_x - Q1_x

            Q1_y = merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'].quantile(0.25)
            Q3_y = merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'].quantile(0.75)
            IQR_y = Q3_y - Q1_y

            merged_df = merged_df[
                (merged_df['ì—…ì†Œë°€ì§‘ë„'] >= Q1_x - 1.5 * IQR_x) & (merged_df['ì—…ì†Œë°€ì§‘ë„'] <= Q3_x + 1.5 * IQR_x) &
                (merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'] >= Q1_y - 1.5 * IQR_y) & (merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'] <= Q3_y + 1.5 * IQR_y)
            ]


        # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        pearson_corr, pearson_p = pearsonr(merged_df['ì—…ì†Œë°€ì§‘ë„'], merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'])
        spearman_corr, spearman_p = spearmanr(merged_df['ì—…ì†Œë°€ì§‘ë„'], merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'])

        # íšŒê·€ì„  ê³„ì‚°
        regression = linregress(merged_df['ì—…ì†Œë°€ì§‘ë„'], merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'])
        regression_line = [{"x": x, "y": regression.slope * x + regression.intercept} for x in merged_df['ì—…ì†Œë°€ì§‘ë„']]

        # ì‚°ì ë„ ë°ì´í„°
        scatter_data = [{"x": row['ì—…ì†Œë°€ì§‘ë„'], "y": row['í­ë ¥ë²”ì£„ë°€ì§‘ë„']} for _, row in merged_df.iterrows()]

        # ìµœëŒ€ê°’
        max_x = merged_df['ì—…ì†Œë°€ì§‘ë„'].max() * 1.1
        max_y = merged_df['í­ë ¥ë²”ì£„ë°€ì§‘ë„'].max() * 1.1

        return merged_df.to_dict(orient='records'), round(pearson_corr, 3), round(pearson_p, 4), round(spearman_corr, 3), round(spearman_p, 4), scatter_data, regression_line, max_x, max_y

    except Exception as e:
        print("ë°€ì§‘ë„ ìƒê´€ë¶„ì„ ì‹¤íŒ¨ : ", e)
        return None, 0, 0, 0, 0, [], [], 0, 0

    finally:
        if conn:
            conn.close()